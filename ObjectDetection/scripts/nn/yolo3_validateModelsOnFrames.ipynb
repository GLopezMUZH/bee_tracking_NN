{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"yolo3_validateModelsOnFrames.ipynb","provenance":[{"file_id":"1JC2p_1vFy1RYxTv8GSZR2Om80doCVA6w","timestamp":1597052519716},{"file_id":"1j5FWHs1JId46ROJQg2H586eB8yvdZsYV","timestamp":1592598201009},{"file_id":"1rbtLzdU57m6e0FF0m79Lg3hZbw9GFrsg","timestamp":1591963842455}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MCXUUE4v184g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1598721463938,"user_tz":-120,"elapsed":18130,"user":{"displayName":"Gabriela López Magaña","photoUrl":"","userId":"15080041573951551186"}},"outputId":"56420e88-101e-4a78-aa28-cd7e595f2d80"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# the project's folder\n","# %cd '/gdrive/My Drive/Colab Notebooks/beeWatch'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r_A8LDvyM7x5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1598721628602,"user_tz":-120,"elapsed":14486,"user":{"displayName":"Gabriela López Magaña","photoUrl":"","userId":"15080041573951551186"}},"outputId":"bf0a63d4-706b-4809-ad01-bf9abf3d2a6d"},"source":["# Unzipping the cuDNN files from your Drive folder directly to the VM CUDA folders\n","!tar -xzvf /content/gdrive/My\\ Drive/darknet/cuDNN/cudnn-10.1-linux-x64-v7.6.5.32.tgz -C /usr/local/ #gabriela\n","#!tar -xzvf /content/gdrive/My\\ Drive/Bees/darknet/cuDNN/cudnn-10.1-linux-x64-v7.6.5.32.tgz -C /usr/local/ #pascal\n","\n","!chmod a+r /usr/local/cuda/include/cudnn.h\n","\n","# Now we check the version we already installed. Can comment this line on future runs\n","!cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda/include/cudnn.h\n","cuda/NVIDIA_SLA_cuDNN_Support.txt\n","cuda/lib64/libcudnn.so\n","cuda/lib64/libcudnn.so.7\n","cuda/lib64/libcudnn.so.7.6.5\n","cuda/lib64/libcudnn_static.a\n","#define CUDNN_MAJOR 7\n","#define CUDNN_MINOR 6\n","#define CUDNN_PATCHLEVEL 5\n","--\n","#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n","\n","#include \"driver_types.h\"\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wp19LW_uEmX6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598721638384,"user_tz":-120,"elapsed":613,"user":{"displayName":"Gabriela López Magaña","photoUrl":"","userId":"15080041573951551186"}},"outputId":"f631bcf8-8a4a-4bd2-c4a1-d975b3e2877f"},"source":["print(cv2.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4.1.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-mHktoLL1kmO","colab_type":"text"},"source":["# Start validadion"]},{"cell_type":"code","metadata":{"id":"7YXDCFOSgNq4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1598721636154,"user_tz":-120,"elapsed":1623,"user":{"displayName":"Gabriela López Magaña","photoUrl":"","userId":"15080041573951551186"}},"outputId":"b5548866-319b-458d-ec47-5bc573b2e4f2"},"source":["#!pip install --force https://github.com/chengs/tqdm/archive/colab.zip\n","import numpy as np\n","import cv2\n","import os\n","import random\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","from tqdm import tqdm\n","import sqlite3\n","from shapely.geometry import Polygon\n","import numpy as np\n","from copy import deepcopy\n","import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","import imutils\n","import time"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"7__s4vAxZzf4","colab_type":"text"},"source":["## Functions"]},{"cell_type":"code","metadata":{"id":"NU_Hko6upzAw","colab_type":"code","colab":{}},"source":["import xml.etree.ElementTree as xmlbuilder\n","import xml.dom.minidom\n","\n","\n","def create_xml_voc_files(bboxes, gt_bboxes, img_sizes, xml_folder_path):\n","  root = xmlbuilder.Element(\"annotation\")\n","  fldr = xmlbuilder.Element(\"folder\")\n","  fldr.text = \"validate\"\n","  root.append(fldr)\n","\n","  for img_file in bboxes.keys():\n","    xml_filename = xml_folder_path + img_file.split('.')[0] + '.xml'\n","\n","    #exit if file exists\n","    if os.path.isfile(xml_filename):\n","      return\n","\n","    flnm = xmlbuilder.Element(\"filename\")\n","    flnm.text = img_file\n","    root.append(flnm)\n","    pth = xmlbuilder.Element(\"path\")\n","    pth.text = img_file\n","    root.append(pth)\n","\n","    src = xmlbuilder.Element(\"source\")\n","    db = xmlbuilder.SubElement(src, \"database\")\n","    db.text = \"Unknown\"\n","    root.append(src)\n","\n","    sz = xmlbuilder.Element(\"size\")\n","    wd = xmlbuilder.SubElement(sz, \"width\")\n","    wd.text = str(img_sizes[0][0])\n","    hg = xmlbuilder.SubElement(sz, \"height\")\n","    hg.text = str(img_sizes[0][1])\n","    dp = xmlbuilder.SubElement(sz, \"depth\")\n","    dp.text = str(3)\n","    root.append(sz)\n","\n","    for box in bboxes[img_file]['boxes']:\n","      detected_bee = xmlbuilder.Element(\"object\")\n","      db_name = xmlbuilder.SubElement(detected_bee, \"name\")\n","      db_name.text = \"detected_bee\"\n","      db_pose = xmlbuilder.SubElement(detected_bee, \"pose\")\n","      db_pose.text = \"Unspecified\"\n","      db_truncated = xmlbuilder.SubElement(detected_bee, \"truncated\")\n","      db_truncated.text = str(0)\n","      db_difficult = xmlbuilder.SubElement(detected_bee, \"difficult\")\n","      db_difficult.text = str(0)\n","      db_bndbox = xmlbuilder.SubElement(detected_bee, \"bndbox\")\n","      db_bndbox_xmin = xmlbuilder.SubElement(db_bndbox, \"xmin\")\n","      db_bndbox_xmin.text = str(box[0])\n","      db_bndbox_ymin = xmlbuilder.SubElement(db_bndbox, \"ymin\")\n","      db_bndbox_ymin.text = str(box[1])\n","      db_bndbox_xmax = xmlbuilder.SubElement(db_bndbox, \"xmax\")\n","      db_bndbox_xmax.text = str(box[2])\n","      db_bndbox_ymax = xmlbuilder.SubElement(db_bndbox, \"ymax\")\n","      db_bndbox_ymax.text = str(box[3])\n","      root.append(detected_bee)\n","\n","    for box in gt_bboxes[img_file]:\n","      gt_bee = xmlbuilder.Element(\"object\")\n","      db_name = xmlbuilder.SubElement(gt_bee, \"name\")\n","      db_name.text = \"gt_bee\"\n","      db_pose = xmlbuilder.SubElement(gt_bee, \"pose\")\n","      db_pose.text = \"Unspecified\"\n","      db_truncated = xmlbuilder.SubElement(gt_bee, \"truncated\")\n","      db_truncated.text = str(0)\n","      db_difficult = xmlbuilder.SubElement(gt_bee, \"difficult\")\n","      db_difficult.text = str(0)\n","      db_bndbox = xmlbuilder.SubElement(gt_bee, \"bndbox\")\n","      db_bndbox_xmin = xmlbuilder.SubElement(db_bndbox, \"xmin\")\n","      db_bndbox_xmin.text = str(box[0])\n","      db_bndbox_ymin = xmlbuilder.SubElement(db_bndbox, \"ymin\")\n","      db_bndbox_ymin.text = str(box[1])\n","      db_bndbox_xmax = xmlbuilder.SubElement(db_bndbox, \"xmax\")\n","      db_bndbox_xmax.text = str(box[2])\n","      db_bndbox_ymax = xmlbuilder.SubElement(db_bndbox, \"ymax\")\n","      db_bndbox_ymax.text = str(box[3])\n","      root.append(gt_bee)\n","\n","    tree = xmlbuilder.ElementTree(root) \n","    \n","    xmlstr = xml.etree.ElementTree.tostring(root, encoding='utf8', method='xml')\n","    dom = xml.dom.minidom.parseString(xmlstr) #xml_string\n","    pretty_xml_as_string = dom.toprettyxml()\n","\n","    with open (xml_filename, \"w\") as files : \n","        files.write(\"%s\\n\" % pretty_xml_as_string)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zZFbxWBrjvg5","colab_type":"code","colab":{}},"source":["def CNN_get_boxes_for_frame(file,image):\n","\n","  predicted = {}\n","  predicted[file] = {}\n","  predicted[file]['boxes'] = []\n","  predicted[file]['scores'] = []\n","  bboxes = []\n","  (W, H) = (None, None)\n","  no_predictions = False\n","\n","  # image = frame\n","\n","  # construct a blob from the input frame and then perform a forward\n","  # pass of the YOLO object detector, giving us our bounding boxes\n","  # and associated probabilities\n","  blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (608, 608), swapRB=True, crop=False)\n","  net.setInput(blob)\n","  start = time.time()\n","  layerOutputs = net.forward(ln)\n","\n","  if W is None or H is None:\n","    (H, W) = image.shape[:2]\n","\n","  # loop over each of the layer outputs\n","  for output in layerOutputs:\n","    # loop over each of the detections\n","    for detection in output:\n","      # extract the class ID and confidence (i.e., probability)\n","      # of the current object detection\n","      scores = detection[5:]\n","      classID = np.argmax(scores)\n","      confidence = scores[classID]\n","      # filter out weak predictions by ensuring the detected\n","      # probability is greater than the minimum probability\n","      if confidence > 0.5:\n","        # scale the bounding box coordinates back relative to\n","        # the size of the image, keeping in mind that YOLO\n","        # actually returns the center (x, y)-coordinates of\n","        # the bounding box followed by the boxes' width and\n","        # height\n","        box = detection[0:4] * np.array([W, H, W, H])\n","        (centerX, centerY, width, height) = box.astype(\"int\")\n","        # use the center (x, y)-coordinates to derive the top\n","        # and and left corner of the bounding box\n","        x_min = int(centerX - (width / 2))\n","        x_max = x_min+width\n","        y_min = int(centerY - (height / 2))\n","        y_max = y_min+height\n","        # update our list of bounding box coordinates,\n","        # confidences, and class IDs\n","        #boxes.append([x, y, int(width), int(height)])\n","        #confidences.append(float(confidence))\n","        #classIDs.append(classID)\n","        #boxes_to_frames.append([framesCaptured,x, y, int(width), int(height),confidence])\n","        predicted[file]['boxes'].append([x_min, y_min, x_max, y_max])\n","        predicted[file]['scores'].append(float(confidence))\n","  if len(predicted[file]['boxes']) == 0:\n","    no_predictions = True\n","  return predicted, no_predictions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ruheA5w7ha2H","colab_type":"code","colab":{}},"source":["def plot_image_and_boxes_on_axis(image, boxes, ax, centers=True, trace=True, title=\"\",color='blue'):\n","    ax.imshow(image[:, :, ::-1])\n","    for i, box_dict in enumerate(boxes):\n","        # box = box_dict['location']\n","        box = box_dict\n","        rect = patches.Rectangle((box[0], box[1]), box[2], box[3], fill=False, lw=2, color=color)\n","\n","        ax.add_patch(rect)\n","        ax.set_axis_off()\n","    ax.title.set_text(title)\n","    return ax"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZSwzt41yhdGp","colab_type":"code","colab":{}},"source":["def calc_iou(gt_bbox, pred_bbox):\n","    '''\n","    This function takes the predicted bounding box and ground truth bounding box and\n","    return the IoU ratio\n","    '''\n","    x_topleft_gt, y_topleft_gt, x_bottomright_gt, y_bottomright_gt = gt_bbox\n","    x_topleft_p, y_topleft_p, x_bottomright_p, y_bottomright_p = pred_bbox\n","\n","    if (x_topleft_gt > x_bottomright_gt) or (y_topleft_gt > y_bottomright_gt):\n","        raise AssertionError(\"Ground Truth Bounding Box is not correct\")\n","    if (x_topleft_p > x_bottomright_p) or (y_topleft_p > y_bottomright_p):\n","        raise AssertionError(\"Predicted Bounding Box is not correct\", x_topleft_p, x_bottomright_p, y_topleft_p,\n","                             y_bottomright_p)\n","\n","    # if the GT bbox and predcited BBox do not overlap then iou=0\n","    if (x_bottomright_gt < x_topleft_p):\n","        # If bottom right of x-coordinate  GT  bbox is less than or above the top left of x coordinate of  the predicted BBox\n","\n","        return 0.0\n","    if (\n","            y_bottomright_gt < y_topleft_p):  # If bottom right of y-coordinate  GT  bbox is less than or above the top left of y coordinate of  the predicted BBox\n","\n","        return 0.0\n","    if (\n","            x_topleft_gt > x_bottomright_p):  # If bottom right of x-coordinate  GT  bbox is greater than or below the bottom right  of x coordinate of  the predcited BBox\n","\n","        return 0.0\n","    if (\n","            y_topleft_gt > y_bottomright_p):  # If bottom right of y-coordinate  GT  bbox is greater than or below the bottom right  of y coordinate of  the predcited BBox\n","\n","        return 0.0\n","\n","    GT_bbox_area = (x_bottomright_gt - x_topleft_gt + 1) * (y_bottomright_gt - y_topleft_gt + 1)\n","    Pred_bbox_area = (x_bottomright_p - x_topleft_p + 1) * (y_bottomright_p - y_topleft_p + 1)\n","\n","    x_top_left = np.max([x_topleft_gt, x_topleft_p])\n","    y_top_left = np.max([y_topleft_gt, y_topleft_p])\n","    x_bottom_right = np.min([x_bottomright_gt, x_bottomright_p])\n","    y_bottom_right = np.min([y_bottomright_gt, y_bottomright_p])\n","\n","    intersection_area = (x_bottom_right - x_top_left + 1) * (y_bottom_right - y_top_left + 1)\n","\n","    union_area = (GT_bbox_area + Pred_bbox_area - intersection_area)\n","\n","    return intersection_area / union_area\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rcPlQvPohcv1","colab_type":"code","colab":{}},"source":["def get_model_scores(pred_boxes):\n","    \"\"\"Creates a dictionary of from model_scores to image ids.\n","    Args:\n","        pred_boxes (dict): dict of dicts of 'boxes' and 'scores'\n","    Returns:\n","        dict: keys are model_scores and values are image ids (usually filenames)\n","    \"\"\"\n","    model_score={}\n","    for img_id, val in pred_boxes.items():\n","        for score in val['scores']:\n","            if score not in model_score.keys():\n","                model_score[score]=[img_id]\n","            else:\n","                model_score[score].append(img_id)\n","    return model_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ER79EsSVhcXR","colab_type":"code","colab":{}},"source":["def calc_precision_recall(image_results):\n","    \"\"\"Calculates precision and recall from the set of images\n","    Args:\n","        img_results (dict): dictionary formatted like:\n","            {\n","                'img_id1': {'true_pos': int, 'false_pos': int, 'false_neg': int},\n","                'img_id2': ...\n","                ...\n","            }\n","    Returns:\n","        tuple: of floats of (precision, recall)\n","    \"\"\"\n","    true_positive=0\n","    false_positive=0\n","    false_negative=0\n","    precision = 0\n","    recall = 0\n","    for img_id, res in image_results.items():\n","        true_positive +=res['true_positive']\n","        false_positive += res['false_positive']\n","        false_negative += res['false_negative']\n","        try:\n","            precision = true_positive/(true_positive+ false_positive)\n","        except ZeroDivisionError:\n","            precision=0.0\n","        try:\n","            recall = true_positive/(true_positive + false_negative)\n","        except ZeroDivisionError:\n","            recall=0.0\n","    return (precision, recall)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JfoWb_OwhcHJ","colab_type":"code","colab":{}},"source":["def get_single_image_results(gt_boxes, pred_boxes, iou_thr):\n","    \"\"\"Calculates number of true_pos, false_pos, false_neg from single batch of boxes.\n","    Args:\n","        gt_boxes (list of list of floats): list of locations of ground truth\n","            objects as [xmin, ymin, xmax, ymax]\n","        pred_boxes (dict): dict of dicts of 'boxes' (formatted like `gt_boxes`)\n","            and 'scores'\n","        iou_thr (float): value of IoU to consider as threshold for a\n","            true prediction.\n","    Returns:\n","        dict: qty_ground_truth (int), qty_predicted (int), true positives (int), false positives (int), false negatives (int)\n","    \"\"\"\n","    all_pred_indices = range(len(pred_boxes))\n","    all_gt_indices = range(len(gt_boxes))\n","    qty_predicted = len(pred_boxes)\n","    qty_ground_truth = len(gt_boxes)\n","    tp = 0\n","    fp = 0\n","    fn = 0\n","    output = \"bla\"\n","\n","    if len(all_pred_indices) == 0:\n","        return {'qty_ground_truth' : qty_ground_truth, 'qty_predicted' : qty_predicted, 'true_positive': tp, 'false_positive': fp, 'false_negative': fn}\n","    if len(all_gt_indices) == 0:\n","        return {'qty_ground_truth' : qty_ground_truth, 'qty_predicted' : qty_predicted, 'true_positive': tp, 'false_positive': fp, 'false_negative': fn}\n","\n","    gt_idx_thr = []\n","    pred_idx_thr = []\n","    ious = []\n","\n","    for ipb, pred_box in enumerate(pred_boxes):\n","        # print(ipb, pred_box)\n","\n","        for igb, gt_box in enumerate(gt_boxes):\n","            # print(igb, gt_box)\n","            iou = calc_iou(gt_box, pred_box)\n","\n","            if iou > iou_thr:\n","                gt_idx_thr.append(igb)\n","                pred_idx_thr.append(ipb)\n","                ious.append(iou)\n","    iou_sort = np.argsort(ious)[::1]\n","    if len(iou_sort) == 0:\n","        return {'qty_ground_truth' : qty_ground_truth, 'qty_predicted' : qty_predicted, 'true_positive': tp, 'false_positive': len(pred_boxes), 'false_negative': fn}\n","    else:\n","        gt_match_idx = []\n","        pred_match_idx = []\n","        for idx in iou_sort:\n","            gt_idx = gt_idx_thr[idx]\n","            pr_idx = pred_idx_thr[idx]\n","            # If the boxes are unmatched, add them to matches\n","            if (gt_idx not in gt_match_idx) and (pr_idx not in pred_match_idx):\n","                gt_match_idx.append(gt_idx)\n","                pred_match_idx.append(pr_idx)\n","        tp = len(gt_match_idx)\n","        fp = len(pred_boxes) - len(pred_match_idx)\n","        fn = len(gt_boxes) - len(gt_match_idx)\n","        output = {'qty_ground_truth' : qty_ground_truth, 'qty_predicted' : qty_predicted, 'true_positive': tp, 'false_positive': fp, 'false_negative': fn}\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mf-XM0gJhbzi","colab_type":"code","colab":{}},"source":["def get_avg_precision_at_iou(image,gt_boxes, pred_bb, no_predictions = False, iou_thr=0.5):\n","  if (no_predictions):\n","    return {image:{'qty_ground_truth' : len(gt_boxes[image]), 'qty_predicted' : 0, 'true_positive': 0, 'false_positive': 0, 'false_negative': len(gt_boxes[image])}}\n","\n","  model_scores = get_model_scores(pred_bb)\n","  sorted_model_scores = sorted(model_scores.keys())\n","  # Sort the predicted boxes in descending order (lowest scoring boxes first):\n","  for img_id in pred_bb.keys():\n","    arg_sort = np.argsort(pred_bb[img_id]['scores'])\n","    pred_bb[img_id]['scores'] = np.array(pred_bb[img_id]['scores'])[arg_sort].tolist()\n","    pred_bb[img_id]['boxes'] = np.array(pred_bb[img_id]['boxes'])[arg_sort].tolist()\n","\n","  pred_boxes_pruned = deepcopy(pred_bb)\n","\n","  precisions = []\n","  recalls = []\n","  model_thrs = []\n","  img_results = {}\n","  img_ids = []\n","  model_score_thr = 0\n","  # Loop over model score thresholds and calculate precision, recall\n","  for ithr, model_score_thr in enumerate(sorted_model_scores[:-1]):\n","    # On first iteration, define img_results for the first time:\n","    # print(\"Model score : \", model_score_thr)\n","    img_ids = gt_boxes.keys() if ithr == 0 else model_scores[model_score_thr]\n","\n","  if len(img_ids) == 0:\n","    print(\"pruned img_ids from after score\", image)\n","    return {image:{'qty_ground_truth' : len(gt_boxes[image]), 'qty_predicted' : 0, 'true_positive': 0, 'false_positive': 0, 'false_negative': len(gt_boxes[image])}}\n","\n","  for img_id in img_ids:\n","    # return if the size of prediction is 0\n","    if len(pred_bb[img_id]['boxes']) == 0:\n","      return {img_id:{'qty_ground_truth' : len(gt_boxes[img_id]), 'qty_predicted' : 0, 'true_positive': 0, 'false_positive': 0, 'false_negative': len(gt_boxes[img_id])}}\n","\n","    gt_boxes_img = gt_boxes[img_id]\n","    box_scores = pred_boxes_pruned[img_id]['scores']\n","    start_idx = 0\n","\n","    for score in box_scores:\n","      if score <= 0:\n","        pred_boxes_pruned[img_id]\n","        start_idx += 1\n","      else:\n","        break\n","        # Remove boxes, scores of lower than threshold scores:\n","    pred_boxes_pruned[img_id]['scores'] = pred_boxes_pruned[img_id]['scores'][start_idx:]\n","    pred_boxes_pruned[img_id]['boxes'] = pred_boxes_pruned[img_id]['boxes'][start_idx:]\n","    # Recalculate image results for this image\n","    img_results[img_id] = get_single_image_results(gt_boxes_img, pred_boxes_pruned[img_id]['boxes'], iou_thr=0.25)\n","    # calculate precision and recall\n","    \n","    #if len(img_results) == 0 and len(pred_bb[img_id]['boxes']) == 0 and len(gt_boxes[img_id]) != 0:\n","    if len(img_results[img_id]) == 0 and len(gt_boxes[img_id]) != 0:\n","      print(\"get_avg_precision_at_iou all predictions were pruned\")\n","      return {img_id:{'qty_ground_truth' : len(gt_boxes[img_id]), 'qty_predicted' : 0, 'true_positive': 0, 'false_positive': 0, 'false_negative': len(gt_boxes[img_id])}}\n","\n","  prec, rec = calc_precision_recall(img_results)\n","  precisions.append(prec)\n","  recalls.append(rec)\n","  model_thrs.append(model_score_thr)\n","  precisions = np.array(precisions)\n","  recalls = np.array(recalls)\n","  prec_at_rec = []\n","  for recall_level in np.linspace(0.0, 1.0, 11):\n","    try:\n","      args = np.argwhere(recalls > recall_level).flatten()\n","      prec = max(precisions[args])\n","      #print(recalls, \"Recall\")\n","      #print(recall_level, \"Recall Level\")\n","      #print(args, \"Args\")\n","      #print(prec, \"precision\")\n","    except ValueError:\n","      prec = 0.0\n","    prec_at_rec.append(prec)\n","  avg_prec = np.mean(prec_at_rec)\n","  return img_results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_7v6AVkZAB9C","colab_type":"code","colab":{}},"source":["#  Felzenszwalb et al.\n","def non_max_suppression_slow(boxes, overlapThresh=0.3):\n","\t# if there are no boxes, return an empty list\n","\tif len(boxes) == 0:\n","\t\treturn []\n","\t# initialize the list of picked indexes\n","\tpick = []\n","\t# grab the coordinates of the bounding boxes\n","\tx1 = boxes[:,0]\n","\ty1 = boxes[:,1]\n","\tx2 = boxes[:,2]\n","\ty2 = boxes[:,3]\n","\t# compute the area of the bounding boxes and sort the bounding\n","\t# boxes by the bottom-right y-coordinate of the bounding box\n","\tarea = (x2 - x1 + 1) * (y2 - y1 + 1)\n","\tidxs = np.argsort(y2)\n"," \t# keep looping while some indexes still remain in the indexes\n","\t# list\n","\twhile len(idxs) > 0:\n","\n","\t\t# grab the last index in the indexes list, add the index\n","\t\t# value to the list of picked indexes, then initialize\n","\t\t# the suppression list (i.e. indexes that will be deleted)\n","\t\t# using the last index\n","\t\tlast = len(idxs) - 1\n","\t\ti = idxs[last]\n","\t\tpick.append(i)\n","\t\tsuppress = [last]\n","    # loop over all indexes in the indexes list\n","\t\tfor pos in range(0, last):\n","\t\t\t# grab the current index\n","\t\t\tj = idxs[pos]\n","\t\t\t# find the largest (x, y) coordinates for the start of\n","\t\t\t# the bounding box and the smallest (x, y) coordinates\n","\t\t\t# for the end of the bounding box\n","\t\t\txx1 = max(x1[i], x1[j])\n","\t\t\tyy1 = max(y1[i], y1[j])\n","\t\t\txx2 = min(x2[i], x2[j])\n","\t\t\tyy2 = min(y2[i], y2[j])\n","\t\t\t# compute the width and height of the bounding box\n","\t\t\tw = max(0, xx2 - xx1 + 1)\n","\t\t\th = max(0, yy2 - yy1 + 1)\n","\t\t\t# compute the ratio of overlap between the computed\n","\t\t\t# bounding box and the bounding box in the area list\n","\t\t\toverlap = float(w * h) / area[j]\n","\t\t\t# if there is sufficient overlap, suppress the\n","\t\t\t# current bounding box\n","\t\t\tif overlap > overlapThresh:\n","\t\t\t\tsuppress.append(pos)\n","\t\t# delete all indexes from the index list that are in the\n","\t\t# suppression list\n","\t\tidxs = np.delete(idxs, suppress)\n","\t# return only the bounding boxes that were picked\n","\treturn pick"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wr-TRydkZ4NP","colab_type":"text"},"source":["## Runtime"]},{"cell_type":"code","metadata":{"id":"4M6UxKemgUla","colab_type":"code","colab":{}},"source":["# Gabriela's paths\n","trained_model = 'yolo3_all_hives' # model = type of training + hive + parameter\n","WEIGHTS_PATH = '/content/gdrive/My Drive/yolo_models/backup_yolo3/yolov3_last.weights'\n","CONFIG_PATH = '/content/gdrive/My Drive/darknet/yolov3_bees.cfg'\n","OUTPUT_PATH = './output' #'/content/gdrive/My Drive/darknet/output/'\n","labelsPath = '/content/gdrive/My Drive/darknet/bee.names'  \n","DB_PATH = '/content/gdrive/My Drive/yolo4_validation/bees.db'\n","IMAGE_PATH = '/content/gdrive/My Drive/darknet/test'\n","PLOT = True #for local testing to inspect images\n","VALIDATION_XML_DIRECTORY_PATH_PREFIX = '/content/gdrive/My Drive/yolo3_validation/'\n","\n","\n","#'/content/gdrive/My Drive/Bees/darknet/obj.data'  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kkiqRFTrwciF","colab_type":"code","colab":{}},"source":["print(cv2.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ge6b_7_ZYLGN","colab_type":"code","colab":{}},"source":["image_list = []\n","validation_xml_directory_path = {}\n","\n","hives = ['Chueried_Hempbox', 'Chueried_Hive01', 'ClemensRed', 'ClemensYellow',\n","        'Doettingen_Hive1', 'Echolinde', 'Echolinde_Night', 'Erlen_Hive04_diagonalview',\n","        'Erlen_Hive04_frontview', 'Erlen_Hive04_smartphone', 'Erlen_Hive11',\n","        'Erlen_Hive11_Night', 'Froh14', 'Froh23_TreeCavity', 'UnitedQueens']\n","\n","\"\"\"\n","hives = ['Chueried_Hive01', 'ClemensYellow',\n","        'Echolinde',\n","        'Erlen_Hive04_frontview']\n","\n","hives = ['Chueried_Hive01', 'Echolinde']\n","\"\"\"\n","\n","for hive in hives:\n","  img_path = '/content/gdrive/My Drive/beeTracking_img_labeling/' + hive + '/validate'\n","  for filename in os.listdir(img_path):\n","      if not filename.endswith('.jpg'): continue\n","      fullname = os.path.join(img_path, filename)\n","      image_list.append(fullname)\n","  \n","  validation_xml_directory_path[hive] = VALIDATION_XML_DIRECTORY_PATH_PREFIX + trained_model + '/' + hive\n","  if not os.path.exists(validation_xml_directory_path[hive]):\n","    print(\"created validation folder: \", validation_xml_directory_path[hive])\n","    os.makedirs(validation_xml_directory_path[hive])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"saEmCZT7sG1J","colab_type":"code","colab":{}},"source":["len(image_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"frMYUxZyxuoa","colab_type":"code","colab":{}},"source":["image_list[170:180]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pNr7MsHbfV57","colab_type":"code","colab":{}},"source":["print(validation_xml_directory_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EmLB4Y9Kj5fg","colab_type":"code","colab":{}},"source":["# load the class labels our YOLO model was trained on\n","LABELS = open(labelsPath).read().strip().split(\"\\n\")\n","# initialize a list of colors to represent each possible class label\n","np.random.seed(42)\n","COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")\n","# derive the paths to the YOLO weights and model configuration"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XSjx_a9OkYWb","colab_type":"code","colab":{}},"source":["# load our YOLO object detector trained on your dataset \n","# and determine only the *output* layer names that we need from YOLO\n","print(\"[INFO] loading YOLO from disk...\")\n","net = cv2.dnn.readNetFromDarknet(CONFIG_PATH, WEIGHTS_PATH)\n","ln = net.getLayerNames()\n","ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ycweIkZmlrF","colab_type":"code","colab":{}},"source":["# arguments\n","args_confidence = 0.5\n","args_threshold = 0.3\n","\n","image_arrays = []\n","\n","\n","for i in tqdm(range(len(image_list))):\n","    img = cv2.imread(image_list[i])\n","    image_arrays.append(img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ujero6BCn7LL","colab_type":"code","colab":{}},"source":["print(image_arrays[0].shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wliqLn3liGSw","colab_type":"code","colab":{}},"source":["conn = sqlite3.connect(DB_PATH)\n","c = conn.cursor()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qaYdZ0brzqSv","colab_type":"code","colab":{}},"source":["conn.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c-wm6EAWubj6","colab_type":"code","colab":{}},"source":["query_str = \"select hive_name, count(distinct(filename)), count(*) from validation_ground_truth where hive_name in (\"\n","for hive in hives:\n","  query_str += \"\\'\" + hive + \"\\',\"\n","query_str = query_str[0:len(query_str)-1]\n","query_str += \") group by hive_name\"\n","\n","print(query_str)\n","\n","c.execute(str(query_str))\n","#print(c.fetchone())\n","\n","test = c.fetchall()\n","\n","for row in test:\n","  print(row)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJAjYiyJmz5N","colab_type":"code","colab":{}},"source":["from time import gmtime, strftime\n","print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zgn0mXjSrFek","colab_type":"code","colab":{}},"source":["results = []\n","PLOT = False\n","for i in tqdm(range(len(image_list)),position=0,leave=True):\n","    filename = image_list[i].split('/')[-1]\n","    print(\"Img File: \", filename)\n","\n","    c.execute(\"select hive_name from validation_ground_truth where filename = '{}'\".format(filename))\n","    hive_name = c.fetchall()[0][0]\n","    print(\"MODEL \"  , trained_model , '/' , hive_name )\n","\n","    bboxes, no_predictions = CNN_get_boxes_for_frame(filename, image_arrays[i])\n","    indices = non_max_suppression_slow(np.array(bboxes[filename]['boxes']))\n","    bboxes[filename]['boxes'] = np.array(bboxes[filename]['boxes'])[indices].tolist()\n","    bboxes[filename]['scores'] = np.array(bboxes[filename]['scores'])[indices].tolist()\n","\n","    print(\"predicted: \",len(bboxes[filename]['boxes']))\n","\n","    c.execute(\"select xmin,ymin,xmax,ymax from validation_ground_truth where filename = '{}'\".format(filename))\n","    ground_truth = c.fetchall()\n","    print(\"actual ground truth: \",len(ground_truth))\n","    gt_bboxes = {}\n","    gt_bboxes[filename] = [list(elem) for elem in ground_truth]\n","\n","    c.execute(\"select width, height from validation_ground_truth where filename = '{}'\".format(filename))\n","    img_sizes = c.fetchall()\n","\n","    xml_folder_path = VALIDATION_XML_DIRECTORY_PATH_PREFIX + trained_model + '/' + hive_name + '/'\n","    create_xml_voc_files(bboxes, gt_bboxes, img_sizes, xml_folder_path)\n","\n","    res = get_avg_precision_at_iou(filename, gt_bboxes, bboxes, no_predictions)\n","    print(res)\n","    if PLOT:\n","        fig, ax = plt.subplots(1, figsize=(20,10))\n","        plot_bboxes = []\n","        for box in bboxes[filename]['boxes']:\n","            plot_bboxes.append([box[0], box[1], box[2]-box[0], box[3]-box[1]])\n","        plot_gt_bboxes = []\n","        for box in gt_bboxes[filename]:\n","            plot_gt_bboxes.append([box[0], box[1], box[2]-box[0], box[3]-box[1]])\n","        ax = plot_image_and_boxes_on_axis(image_arrays[i], plot_bboxes, ax,color='blue')\n","        ax = plot_image_and_boxes_on_axis(image_arrays[i], plot_gt_bboxes, ax,color='green')\n","        plt.show()\n","    results.append(res)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"avW7D_TGm1s2","colab_type":"code","colab":{}},"source":["print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WJUa4oyYdVfz","colab_type":"code","colab":{}},"source":["results_file_path = VALIDATION_XML_DIRECTORY_PATH_PREFIX + trained_model + '/validation_results.csv'\n","if not os.path.isfile(results_file_path):\n","  print(results_file_path)\n","  results_file = open(results_file_path, 'w')\n","  results_file.write(\"model,img_file,qty_ground_truth,qty_predicted,true_positive,false_positive,false_negative\\n\")\n","  for r in results:\n","    for k,v in r.items():^\n","      line_str = trained_model + ','\n","      line_str = k + ','\n","      line_str += str(v['qty_ground_truth']) + ','\n","      line_str += str(v['qty_predicted']) + ','\n","      line_str += str(v['true_positive']) + ','\n","      line_str += str(v['false_positive']) + ','\n","      line_str += str(v['false_negative'])\n","    results_file.write(\"%s\\n\" % line_str)\n","  results_file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cq4l7xYrvgat","colab_type":"code","colab":{}},"source":["for r in results:\n","    for k,v in r.items():\n","      print(v['qty_ground_truth'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i6NGxd9ZRElO","colab_type":"code","colab":{}},"source":["for r in results:\n","  print(r)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SLjGx1eLh4LM","colab_type":"code","colab":{}},"source":["output = pd.DataFrame()\n","for i in results:\n","    d = {}\n","    for k,v in i.items():\n","        d['frame'] = k\n","        for kk,vv in v.items():\n","            d[kk] = vv\n","    output = output.append(d,ignore_index=True)\n","\n","output = output[['frame', 'true_positive','false_positive','false_negative']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l820WGGlOWLz","colab_type":"code","colab":{}},"source":["output = output.dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KNOqT8dlh322","colab_type":"code","colab":{}},"source":["total_true_positive = output['true_positive'].sum()\n","total_false_negative = output['false_negative'].sum()\n","total_false_positive = output['false_positive'].sum()\n","\n","all_names = []\n","for name in output.frame:\n","    try:\n","      all_names.append(name.split('_')[0])\n","    except:\n","      all_names.append(name)\n","\n","for u_name in list(set(all_names)):\n","    print(u_name)\n","    filtered_df = output.loc[output['frame'].str.contains(u_name)]\n","    true_positive = filtered_df['true_positive'].sum()\n","    print(\"TP: {}\".format(true_positive))\n","    false_negative = filtered_df['false_negative'].sum()\n","    print(\"FN: {}\".format(false_negative))\n","    false_positive = filtered_df['false_positive'].sum()\n","    print(\"FP: {}\".format(false_positive))\n","    print(\"{} images\".format(len(filtered_df)))\n","    print(\"Precision: {}\".format(true_positive/(true_positive+false_positive)))\n","    print(\"Recall: {}\".format(true_positive / (true_positive + false_negative)))\n","    print(\"_____________________________________________________________\")\n","print(\"Model name: {}\".format(WEIGHTS_PATH.split('/')[-1]))\n","print(\"Overall TP: {}\".format(total_true_positive))\n","print(\"Overall FN: {}\".format(total_false_negative))\n","print(\"Overall FP: {}\".format(total_false_positive))\n","print(\"{} images\".format(len(output)))\n","print(\"Overall Precision: {}\".format(total_true_positive/(total_true_positive+total_false_positive)))\n","print(\"Overall Recall: {}\".format(total_true_positive / (total_true_positive + total_false_negative)))\n","print(\"_____________________________________________________________\")\n","print(\"_____________________________________________________________\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0kmvqTnABItQ","colab_type":"text"},"source":["### Counting"]},{"cell_type":"code","metadata":{"id":"RH5dMzt4H0Je","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}